# -*- coding: utf-8 -*-
"""Precipitações - Tianguá - 10-fold.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PoiYOdFSCD2k6rNXWQjhahYd-3nvOo1q

**Título:** Avaliação de Desempenho de Classificadores a Partir de Dados Relacionados a Precipitação Pluviométrica Coletados por Estação Meteorológica Automática

**Autores:** Ananias C. de Oliveira, Rhyan X. de Brito, Maria A. O. Chaves, Roney N. de Sousa, Adonias C. de Oliveira, Paulo C. de Almeida Júnior.

**Autores do código:** Ananias Caetano de Oliveira, Roney Nogueira de Sousa, Adonias Caetano de Oliveira

**Orientadores:** Rhyan Ximenes de Brito, Adonias Caetano de Oliveira e Paulo César de Almeida Júnior

**Coordenador do projeto:** Rhyan Ximenes de Brito

**Curso:** Bacharelado em Ciência da Computação

**Instituição:** Instituto Federal de Educação, Ciência e Tecnologia do Ceará (IFCE) Campus Tianguá
"""

!pip install plotly --upgrade

!pip install -q "tqdm>=4.36.1"

!pip install colorama

!pip install lime

"""#**Etapa 1: Leitura do dataset TIANGUA(A368) de Precipitações**

**Descrição do dataset:** O dataset possui 27695 registros e 19 atributos, dos quais o último atributo "Chuva (mm)" determina a quantidade em milímetros de chuva para um período.

Disponível em: [ZENODO](https://zenodo.org/records/14914786)

**Atributos:**

* **Data:** Data de registro;
* **Hora (UTC):** Hora de registro;
* **Temp. Ins. (C):** Temperatura Instantânea do Ar;
* **Temp. Max. (C):** Temperatura Máxima do Ar;
* **Temp. Min. (C):** Temperatura Mínima do Ar;
* **Umi. Ins. (%):** Umidade Relativa Instantânea do Ar;
* **Umi. Max. (%):** Umidade Relativa Máxima do Ar;
* **Umi. Min. (%):** Umidade Relativa Mínima do Ar;
* **Pto Orvalho Ins. (C):** Temperatura Instantânea do Ponto de Orvalho;
* **Pto Orvalho Max. (C):** Temperatura Máxima do Ponto de Orvalho;
* **Pto Orvalho Min. (C):** Temperatura Mínima do Ponto de Orvalho;
* **Pressao Ins. (hPa):** Pressão Atmosférica Instantânea do Ar;
* **Pressao Max. (hPa):** Pressão Atmosférica Máxima do Ar;
* **Pressao Min. (hPa):** Pressão Atmosférica Mínima do Ar;
* **Vel. Vento (m/s):** Velocidade Instantânea do Vento;
* **Dir. Vento (m/s):** Direção do Vento;
* **Raj. Vento (m/s):** Intensidade da Rajada do Vento;
* **Radiacao (KJ/m²):** Radiação Solar;
* **Chuva (mm):** Precipitação acumulada no período;
"""

# Importando biblioteca pandas
import pandas as pd
import numpy as np
# PLOTS
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
from plotly import figure_factory as ff
from tqdm import tqdm
from colorama import Fore
# PRÉ PROCESSO
from imblearn.under_sampling import RandomUnderSampler
from scipy import stats
from sklearn.manifold import TSNE
# METODOS DE CLASSIFICAÇÃO
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.ensemble import VotingClassifier
# MÉTODO DE EXPLICAÇÃO
import lime
from lime import lime_tabular
#----------------------------------------------------------------------
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import warnings

"""**(2) Adicionando a base de dados de Tianguá da Estação Meteorológica do INMET**"""

url = 'https://drive.google.com/file/d/1HJbTuR4dcYO43OhDmISWyid297386oY9/view?usp=sharing'
file_id = url.split('/')[-2]
read_url='https://drive.google.com/uc?id=' + file_id

# read the data
base = pd.read_csv(read_url, encoding = 'UTF-8', sep=';', decimal=",")

# display the first 5 rows
base.head()

base

"""**Descrição da base de dados**"""

base.describe()

"""**Número de registros 'NaN' para cada atributo**"""

base.isnull().sum()

"""**Gerando uma cópia da base de dados que irá sofrer o Pré-Processamento**"""

dataset = base.copy()

"""#**Etapa 2: Pré-processamento de dados**"""

def plot_tsne(X, y):
  # Aplicar t-SNE
  tsne = TSNE(n_components=2, random_state=42)
  X_tsne = tsne.fit_transform(X)

  # Criar gráfico de dispersão
  plt.figure(figsize=(8, 6))
  plt.scatter(X_tsne[y == 1, 0], X_tsne[y == 1, 1], c='red', label='Ocorreu precipitação')
  plt.scatter(X_tsne[y == 0, 0], X_tsne[y == 0, 1], c='blue', label='Não ocorreu precipitação')

  # Adicionar rótulos e legenda
  plt.xlabel('t-SNE Componente 1')
  plt.ylabel('t-SNE Componente 2')
  plt.title('Distribuição de Instâncias por Classe (t-SNE)')
  plt.legend()

  # Mostrar gráfico
  plt.show()

"""**(1) Remoção dos registros com atributo "Chuva (mm)" vazios**"""

# removendo colunas que não serão usadas
# apagar somente os registros sem resultados
dataset.dropna(subset=['Chuva (mm)'], inplace=True)
dataset.dropna(subset=['Umi. Ins. (%)'], inplace=True)
dataset.dropna(subset=['Umi. Max. (%)'], inplace=True)
dataset.dropna(subset=['Pto Orvalho Max. (C)'], inplace=True)
dataset.dropna(subset=['Vel. Vento (m/s)'], inplace=True)
dataset = dataset.drop(columns=['Radiacao (KJ/m²)'])
dataset = dataset.drop(columns=['Unnamed: 19'])

dataset

"""**Número de registros 'NaN' para cada atributo**"""

dataset.isnull().sum()

"""**(2) Substituindo a Data por o número de dias do ano**

É substituido a data por o número de dias do ano para a data respectiva, assim apenas guardando o periodo do ano.
"""

Data_tempo = dataset.iloc[:, 0:1]
dias_mes = np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])
dias_ano = np.array([365, 365, 366, 365]) # 2018 a 2021

for i in dataset.index:
  date = dataset.loc[i, 'Data']
  array_data = date.split('/')
  hora = int(dataset.loc[i, 'Hora (UTC)'])

  dia = int(array_data[0])
  mes = int(array_data[1])
  ano = int(array_data[2])
  hora = int(hora/100)

  # Calcula a quantidade de dias do ano não bissexto
  dias_somados = dia + dias_mes[0:mes-1].sum() + dias_ano[0:(ano-2018)].sum()

  # Se o ano for bissexto adiciona 1 dia.
  if mes > 2 and (ano%4==0 and ano%100!=0 or ano%400==0):
    dias_somados += 1
  dataset.loc[i, 'Data'] = str(ano)+'-'+str(mes)+'-'+str(dia)+' '+str(hora)+':00:00'
  Data_tempo.loc[i, 'Data'] = dias_somados

"""**Tornando Data como datetime**"""

dataset['Data'] = pd.to_datetime(dataset['Data'])

"""**Tornando Data como index da base**"""

dataset = dataset.set_index('Data')
dataset = dataset.drop(columns=['Hora (UTC)'])

"""**(3) Tornando a ultima coluna como 0 e 1**"""

dataset.loc[dataset['Chuva (mm)'] > 0, 'Chuva (mm)'] = 1  # atualizando o campo para a média
dataset["Chuva (mm)"] = dataset["Chuva (mm)"].astype(int)

dataset

"""**(4) Separando a base de dados em conjunto de atributos e atributo alvo**"""

Data = dataset.index # Registro de Dia e Hora - Dia 74 (15/03/2018) a Dia 1227 (11/05/2021)
X = dataset.iloc[:, 0:15].values # X
y = dataset.iloc[:, 15].values # Y

print('X:\n', X)
print('y:\n', y)
print('\nX Shape: ', X.shape)
print('\ny Shape: ', y.shape)

"""**(5) Aplicando UnderSampler para Balancear as classes**"""

undersample = RandomUnderSampler()
X_processed, y = undersample.fit_resample(X, y)

print('X_process:\n', X_processed)
print('y_process:\n', y)
print('\nX_process Shape: ', X_processed.shape)
print('\ny_process Shape: ', y.shape)

"""**(6) Normalizando os dados usando Z-Score**"""

X_scaled = stats.zscore(X_processed)

print('X__scaled:\n', X_scaled)

# Exemplo de DataFrame (substitua pelos seus dados)
data = {'y': y}
df = pd.DataFrame(data)#

# Mapear valores numéricos para nomes de classes
class_names = {0: 'Não ocorreu precipitação', 1: 'Ocorreu precipitação'}
df['y_names'] = df['y'].map(class_names)

# Criar countplot com cores distintas e rótulos
plt.figure(figsize=(8, 6))
ax = sns.countplot(x='y_names', data=df, palette=['skyblue', 'salmon'])

# Adicionar rótulos e título
plt.xlabel('Classe')
plt.ylabel('Contagem')
plt.title('Contagem de Instâncias por Classe')

# Mostrar gráfico
plt.show()

plot_tsne(X_scaled, y)

"""# **Etapa 3: Classificação**

**Implementando ELM para utilização na classificação**
"""

from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.preprocessing import LabelBinarizer

class ELM(BaseEstimator, ClassifierMixin):
    def __init__(self, n_hidden=100, activation='sigmoid'):
        self.n_hidden = n_hidden
        self.activation = activation

    def _sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def _relu(self, x):
        return np.maximum(0, x)

    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.weights_hidden = np.random.randn(n_features, self.n_hidden)
        self.bias_hidden = np.random.randn(1, self.n_hidden)

        hidden_output = self._activate(np.dot(X, self.weights_hidden) + self.bias_hidden)

        if len(np.unique(y)) > 2:  # Classificação multiclasse
            self.label_binarizer = LabelBinarizer()
            y_bin = self.label_binarizer.fit_transform(y)
            self.weights_output = np.linalg.pinv(hidden_output).dot(y_bin)
        else:  # Classificação binária
            self.weights_output = np.linalg.pinv(hidden_output).dot(y)

        return self

    def predict(self, X):
        hidden_output = self._activate(np.dot(X, self.weights_hidden) + self.bias_hidden)
        output = np.dot(hidden_output, self.weights_output)

        if hasattr(self, 'label_binarizer'):  # Classificação multiclasse
            return self.label_binarizer.inverse_transform(output)
        else:  # Classificação binária
            return np.round(output).flatten()

    def _activate(self, x):
        if self.activation == 'sigmoid':
            return self._sigmoid(x)
        elif self.activation == 'relu':
            return self._relu(x)
        else:
            raise ValueError("Activation must be 'sigmoid' or 'relu'")

"""**Definindo máximo de rodadas e tamanho da base de teste**

## **Validação cruzada: K-fold com k = 10**
Divisão do conjunto de dados em treinamento, validação e teste
"""

#%% separar dados de treinamento e dados de teste

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 0)

"""## **Ajuste fino dos modelos**"""

def ajuste_fino(model, param_grid, X_train, y_train):
  # Criando o objeto GridSearchCV
  grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, scoring='accuracy')

  # Ajustando o GridSearchCV aos dados
  grid_search.fit(X_train, y_train)

  # Obtendo o melhor modelo e os melhores parâmetros
  return grid_search.best_estimator_, grid_search.best_params_

"""### **Ajuste fino do Logistic Regression Classifier**"""

param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],
              'penalty': ['l1', 'l2'],
              'solver': ['liblinear', 'saga']}

best_model_lr, best_params_lr = ajuste_fino(LogisticRegression(), param_grid, X_train, y_train)
# Imprimir os melhores parâmetros
print("Melhores parâmetros Logistic Regression:", best_params_lr)

"""### **Ajuste fino do Naive Bayes Classifier**"""

param_grid = {'var_smoothing': np.logspace(0, -9, num=100)}
best_model_nb, best_params_nb = ajuste_fino(GaussianNB(), param_grid, X_train, y_train)
# Imprimir os melhores parâmetros
print("Melhores parâmetros Naive Bayes:", best_params_nb)

"""### **Ajuste fino do Extra Tree Classifier**"""

# Definindo os hiperparâmetros a serem testados
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

best_model_et, best_params_et = ajuste_fino(ExtraTreesClassifier(random_state=42), param_grid, X_train, y_train)

# Obtendo o melhor modelo e os melhores parâmetros
print("Melhores parâmetros ET:", best_params_et)

"""### **Ajuste fino do Random Forest Classifier**"""

# Definindo os hiperparâmetros a serem testados
param_grid = {
  'n_estimators': [50, 100, 200],
  'criterion': ['gini', 'entropy'],
  'max_depth': [None, 5, 10],
  'max_features': ['sqrt'],
  'min_samples_split': [2, 5, 10],
  'min_samples_leaf': [1, 2, 4]
}

best_model_rf, best_params_rf = ajuste_fino(RandomForestClassifier(), param_grid, X_train, y_train)

# Obtendo o melhor modelo e os melhores parâmetros
print("Melhores parâmetros RF:", best_params_rf)

"""### **Ajuste fino do SVM Classifier**"""

# Definindo os hiperparâmetros a serem testados
param_grid = {'kernel':('linear', 'rbf'), 'C':[1, 10]}

best_model_svm, best_params_svm = ajuste_fino(SVC(), param_grid, X_train, y_train)

# Imprimir os melhores parâmetros
print("Melhores parâmetros SVM:", best_params_svm)

"""### **Ajuste fino do KNN Classifier**"""

# Definindo os hiperparâmetros a serem testados
param_grid = {'n_neighbors': [3, 5, 7, 9, 11],
              'weights': ['uniform', 'distance'],
              'metric': ['euclidean', 'manhattan']}

best_model_knn, best_params_knn = ajuste_fino(KNeighborsClassifier(), param_grid, X_train, y_train)

# Imprimir os melhores parâmetros
print("Melhores parâmetros K-NN:", best_params_knn)

"""### **Ajuste fino do MLP Classifier**"""

# Definindo os hiperparâmetros a serem testados
param_grid = {
    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],
    'activation': ['relu', 'tanh'],
    'alpha': [0.0001, 0.001, 0.01],
    'learning_rate': ['constant', 'adaptive']
}

best_model_mlp, best_params_mlp = ajuste_fino(MLPClassifier(max_iter=1000, random_state=42), param_grid, X_train, y_train)

# Imprimir os melhores parâmetros
print("Melhores parâmetros MLP:", best_params_mlp)

"""## **Ajuste fino do ELM Classifier**"""

# Definindo os hiperparâmetros a serem testados
param_grid = {
    'n_hidden': [60, 100, 200, 300],
    'activation': ['sigmoid', 'relu']
}

best_model_elm, best_params_elm = ajuste_fino(ELM(), param_grid, X_train, y_train)

# Imprimir os melhores parâmetros
print("Melhores parâmetros ELM:", best_params_elm)

"""### **Construindo o modelo ensemble**"""

#%% Ensemble model (Voting)

model_voting = VotingClassifier(
  estimators = [('LR', best_model_lr),
                ('KNN', best_model_knn),
                ('SVC', best_model_svm),
                ('RF', best_model_rf)],
  voting = 'hard'
)

model_voting.fit(X_train, y_train)

"""#**Etapa 4: Avaliação dos Resultados**

## **Matriz de confusão**
"""

from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix
def plot_confusion_matrix(y_preds, y_true, labels=None):
  cm = confusion_matrix(y_true, y_preds, normalize="true")
  fig, ax = plt.subplots(figsize=(6, 6))
  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
  disp.plot(cmap="Blues", values_format=".2f", ax=ax, colorbar=False)
  plt.title("Normalized confusion matrix")
  plt.show()

label_names = ["Não ocorreu preciptação", "Ocorreu precipitação"]

"""### **Avaliação do Logistic Regression**"""

#%% predição nos dados de teste
y_pred = best_model_lr.predict(X_test)

print('classifiation report')
print(classification_report(y_pred, y_test, target_names=label_names))

plot_confusion_matrix(y_pred, y_test,labels=label_names)

"""### **Avaliação do Naive Bayes**"""

#%% predição nos dados de teste
y_pred = best_model_nb.predict(X_test)

print('classifiation report')
print(classification_report(y_pred, y_test, target_names=label_names))

plot_confusion_matrix(y_pred, y_test,labels=label_names)

"""### **Avaliação do Extra Tree**"""

#%% predição nos dados de teste
y_pred = best_model_et.predict(X_test)

print('classifiation report')
print(classification_report(y_pred, y_test, target_names=label_names))

plot_confusion_matrix(y_pred, y_test,labels=label_names)

"""### **Avaliação do Random Forest**"""

#%% predição nos dados de teste
y_pred = best_model_rf.predict(X_test)

print('classifiation report')
print(classification_report(y_pred, y_test, target_names=label_names))

plot_confusion_matrix(y_pred, y_test,labels=label_names)

"""### **Avaliação do SVM**"""

#%% predição nos dados de teste
y_pred = best_model_svm.predict(X_test)

print('classifiation report')
print(classification_report(y_pred, y_test, target_names=label_names))

plot_confusion_matrix(y_pred, y_test,labels=label_names)

"""### **Avaliação do K-NN**"""

#%% predição nos dados de teste
y_pred = best_model_knn.predict(X_test)

print('classifiation report')
print(classification_report(y_pred, y_test, target_names=label_names))

"""### **Avaliação do MLP**"""

#%% predição nos dados de teste
y_pred = best_model_mlp.predict(X_test)

print('classifiation report')
print(classification_report(y_pred, y_test, target_names=label_names))

plot_confusion_matrix(y_pred, y_test,labels=label_names)

"""### **Avaliação do Ensemble**"""

#%% predição nos dados de teste
y_pred = model_voting.predict(X_test)

print('classifiation report')
print(classification_report(y_pred, y_test, target_names=label_names))

plot_confusion_matrix(y_pred, y_test,labels=label_names)

"""### **Avaliação do ELM**"""

#%% predição nos dados de teste
y_pred = best_model_elm.predict(X_test)

# Limiar
threshold = 0.5

# Converter saída em binária
y_pred = np.where(y_pred >= threshold, 1, 0)

print('classifiation report')
print(classification_report(y_pred, y_test, target_names=label_names))

plot_confusion_matrix(y_pred, y_test,labels=label_names)

"""# **Etapa 6: Explicação dos modelos por meio do LIME**"""

# Number denoting the top features
k = 15

"""## **Explicação do modelo Logistic Regression**"""

explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data=np.array(X_train),
    feature_names=dataset.columns[:-1],
    class_names=np.unique(y_train),
    mode='classification'
)

for i in range(10):
  exp_lime = explainer.explain_instance(X_test[i], best_model_lr.predict_proba, num_features=k)
  exp_lime.show_in_notebook()

"""## **Explicação do modelo Naive Bayes**"""

for i in range(10):
  exp_lime = explainer.explain_instance(X_test[i], best_model_nb.predict_proba, num_features=k)
  exp_lime.show_in_notebook()

"""## **Explicação do modelo Extra Tree**"""

for i in range(10):
  exp_lime = explainer.explain_instance(X_test[i], best_model_et.predict_proba, num_features=k)
  exp_lime.show_in_notebook()

"""## **Explicação do modelo Random Forest**"""

for i in range(10):
  exp_lime = explainer.explain_instance(X_test[i], best_model_rf.predict_proba, num_features=k)
  exp_lime.show_in_notebook()

"""## **Explicação do modelo K-NN**"""

for i in range(10):
  exp_lime = explainer.explain_instance(X_test[i], best_model_knn.predict_proba, num_features=k)
  exp_lime.show_in_notebook()

"""## **Explicação do modelo MLP**"""

for i in range(10):
  exp_lime = explainer.explain_instance(X_test[i], best_model_mlp.predict_proba, num_features=k)
  exp_lime.show_in_notebook()